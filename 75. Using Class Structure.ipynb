{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5041,
     "status": "ok",
     "timestamp": 1683179469307,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "vkYFU7wXDtuO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from torchsummary import summary\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "os.chdir(\"D:/Training/Academy/ML(Python)/Cases/Glass_Identification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1683179500202,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "S2EmwO2sDtuV",
    "outputId": "d8bb0752-9828-438f-abf3-4d7663bf8c18"
   },
   "outputs": [],
   "source": [
    "glass = pd.read_csv(\"Glass.csv\")\n",
    "dum_gls = pd.get_dummies(glass)\n",
    "X = dum_gls.iloc[:,:-6]\n",
    "y = dum_gls.iloc[:,-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((214, 9), (214, 6))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1285,
     "status": "ok",
     "timestamp": 1683179502308,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "EGEz_Td9DtuX"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values, test_size = 0.3, \n",
    "                                                    random_state=24,stratify=glass['Type'])\n",
    "X_scl_trn = scaler.fit_transform(X_train) \n",
    "X_scl_tst = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1683180139474,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "VxWSobXXDtuY",
    "outputId": "2362778d-49d1-434a-a5f2-9827f9fdc86c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([149, 9])\n",
      "torch.Size([149, 6])\n"
     ]
    }
   ],
   "source": [
    "X_torch = torch.from_numpy(X_scl_trn)\n",
    "y_torch = torch.from_numpy(y_train)\n",
    "print(X_torch.size())\n",
    "print(y_torch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683179508131,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "PH1DSCQy-EXU",
    "outputId": "dee3d4a3-e0b5-4116-fad0-2c1765b92927"
   },
   "outputs": [],
   "source": [
    "joint_dataset = TensorDataset(X_torch.float(), y_torch.float())\n",
    "torch.manual_seed(25)\n",
    "data_loader = DataLoader(dataset=joint_dataset, batch_size=40, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 791,
     "status": "ok",
     "timestamp": 1683179820324,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "XM5CLc5DDtua"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(25)\n",
    "model = nn.Sequential(nn.Linear(in_features=X_scl_trn.shape[1],out_features=7),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(in_features=7,out_features=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 18]             180\n",
      "              ReLU-2                   [-1, 18]               0\n",
      "            Linear-3                    [-1, 7]             133\n",
      "              ReLU-4                    [-1, 7]               0\n",
      "            Linear-5                    [-1, 6]              48\n",
      "================================================================\n",
      "Total params: 361\n",
      "Trainable params: 361\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(25)\n",
    "class MLPClassifier(torch.nn.Module):    \n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features=num_features, out_features=18)\n",
    "        self.linear2 = nn.Linear(in_features=18, out_features=7)\n",
    "        self.linear3 = nn.Linear(in_features=7, out_features=6)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.act1(x) \n",
    "        output = self.linear3(x)\n",
    "        return output\n",
    "    \n",
    "model = MLPClassifier(num_features=X_scl_trn.shape[1])\n",
    "summary(model, input_size=(X_scl_trn.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683180046576,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "HvVACcd9Dtuc",
    "outputId": "aa120230-79ac-45f2-ee69-089b43c3b916"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    decoupled_weight_decay: True\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.1\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.1)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating predictions with default weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1133,
     "status": "ok",
     "timestamp": 1683180154305,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "AQuAeAiBDtue",
    "outputId": "404fcc09-37be-4046-a484-4926bf948fe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1743, -0.1118, -0.0287,  0.3207, -0.2508,  0.2074],\n",
       "        [-0.1457, -0.1159, -0.0247,  0.3076, -0.2559,  0.2098],\n",
       "        [-0.1703, -0.1054, -0.0348,  0.3118, -0.2533,  0.2048]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_torch.float())\n",
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([149, 6])\n"
     ]
    }
   ],
   "source": [
    "print(y_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([149, 6])\n",
      "torch.Size([149, 6])\n"
     ]
    }
   ],
   "source": [
    "#y_torch = y_torch.unsqueeze(1)\n",
    "print(y_torch.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8491, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(y_pred, y_torch.float())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4436,
     "status": "ok",
     "timestamp": 1683180802989,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "ntZuOAASDtug",
    "outputId": "2472ec9e-b97c-4c9c-ce78-12dc2451b3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  train loss:  1.5168278217315674\n",
      "epoch:  11  train loss:  0.8189548254013062\n",
      "epoch:  21  train loss:  0.7209847569465637\n",
      "epoch:  31  train loss:  0.8077502250671387\n",
      "epoch:  41  train loss:  0.7205083966255188\n",
      "epoch:  51  train loss:  0.6115272045135498\n",
      "epoch:  61  train loss:  0.5379316210746765\n",
      "epoch:  71  train loss:  0.7398132085800171\n",
      "epoch:  81  train loss:  0.4064161777496338\n",
      "epoch:  91  train loss:  0.7619203329086304\n",
      "epoch:  101  train loss:  0.8782759308815002\n",
      "epoch:  111  train loss:  0.6561407446861267\n",
      "epoch:  121  train loss:  0.5936513543128967\n",
      "epoch:  131  train loss:  0.7434694170951843\n",
      "epoch:  141  train loss:  0.7992744445800781\n",
      "epoch:  151  train loss:  0.7233046889305115\n",
      "epoch:  161  train loss:  0.680391788482666\n",
      "epoch:  171  train loss:  0.41054511070251465\n",
      "epoch:  181  train loss:  0.5192486643791199\n",
      "epoch:  191  train loss:  0.6631753444671631\n",
      "epoch:  201  train loss:  0.5228184461593628\n",
      "epoch:  211  train loss:  0.579666018486023\n",
      "epoch:  221  train loss:  0.5964452028274536\n",
      "epoch:  231  train loss:  0.6651917099952698\n",
      "epoch:  241  train loss:  0.4765065014362335\n",
      "epoch:  251  train loss:  0.5977331399917603\n",
      "epoch:  261  train loss:  0.722756028175354\n",
      "epoch:  271  train loss:  0.370793879032135\n",
      "epoch:  281  train loss:  0.7902736663818359\n",
      "epoch:  291  train loss:  0.738598108291626\n",
      "epoch:  301  train loss:  0.6640077829360962\n",
      "epoch:  311  train loss:  0.4948340654373169\n",
      "epoch:  321  train loss:  0.6896252036094666\n",
      "epoch:  331  train loss:  0.6613548994064331\n",
      "epoch:  341  train loss:  0.6070818305015564\n",
      "epoch:  351  train loss:  0.5965605974197388\n",
      "epoch:  361  train loss:  0.5444095134735107\n",
      "epoch:  371  train loss:  0.6145670413970947\n",
      "epoch:  381  train loss:  0.5006423592567444\n",
      "epoch:  391  train loss:  0.5434165596961975\n",
      "epoch:  401  train loss:  0.6690433025360107\n",
      "epoch:  411  train loss:  0.5448318719863892\n",
      "epoch:  421  train loss:  0.5662859082221985\n",
      "epoch:  431  train loss:  0.764226496219635\n",
      "epoch:  441  train loss:  0.6340928077697754\n",
      "epoch:  451  train loss:  0.6391039490699768\n",
      "epoch:  461  train loss:  0.657091498374939\n",
      "epoch:  471  train loss:  0.6771998405456543\n",
      "epoch:  481  train loss:  0.7808429598808289\n",
      "epoch:  491  train loss:  0.6281136274337769\n",
      "epoch:  501  train loss:  0.635297954082489\n",
      "epoch:  511  train loss:  0.6417189240455627\n",
      "epoch:  521  train loss:  0.7072973847389221\n",
      "epoch:  531  train loss:  0.6908249258995056\n",
      "epoch:  541  train loss:  0.5577200055122375\n",
      "epoch:  551  train loss:  0.28608107566833496\n",
      "epoch:  561  train loss:  0.7566666603088379\n",
      "epoch:  571  train loss:  0.688229501247406\n",
      "epoch:  581  train loss:  0.6193216443061829\n",
      "epoch:  591  train loss:  0.5671952366828918\n",
      "epoch:  601  train loss:  0.44147151708602905\n",
      "epoch:  611  train loss:  0.49195143580436707\n",
      "epoch:  621  train loss:  0.6065816283226013\n",
      "epoch:  631  train loss:  0.4850907623767853\n",
      "epoch:  641  train loss:  0.6372489929199219\n",
      "epoch:  651  train loss:  0.5285693407058716\n",
      "epoch:  661  train loss:  0.562502920627594\n",
      "epoch:  671  train loss:  0.4728100001811981\n",
      "epoch:  681  train loss:  1.3077726364135742\n",
      "epoch:  691  train loss:  0.49390262365341187\n",
      "epoch:  701  train loss:  0.4253730773925781\n",
      "epoch:  711  train loss:  0.7617984414100647\n",
      "epoch:  721  train loss:  0.7211050987243652\n",
      "epoch:  731  train loss:  0.5533924698829651\n",
      "epoch:  741  train loss:  0.4840104281902313\n",
      "epoch:  751  train loss:  0.46400511264801025\n",
      "epoch:  761  train loss:  0.5246491432189941\n",
      "epoch:  771  train loss:  0.6207711696624756\n",
      "epoch:  781  train loss:  0.619371235370636\n",
      "epoch:  791  train loss:  0.7170348763465881\n",
      "epoch:  801  train loss:  0.6507705450057983\n",
      "epoch:  811  train loss:  0.5475951433181763\n",
      "epoch:  821  train loss:  0.5379588007926941\n",
      "epoch:  831  train loss:  0.5728112459182739\n",
      "epoch:  841  train loss:  0.422693133354187\n",
      "epoch:  851  train loss:  0.784037709236145\n",
      "epoch:  861  train loss:  0.4644847810268402\n",
      "epoch:  871  train loss:  0.5621535181999207\n",
      "epoch:  881  train loss:  0.9967523217201233\n",
      "epoch:  891  train loss:  0.561223566532135\n",
      "epoch:  901  train loss:  0.5498425960540771\n",
      "epoch:  911  train loss:  0.4445514380931854\n",
      "epoch:  921  train loss:  0.5760204195976257\n",
      "epoch:  931  train loss:  0.3966829776763916\n",
      "epoch:  941  train loss:  0.6075664162635803\n",
      "epoch:  951  train loss:  0.7160883545875549\n",
      "epoch:  961  train loss:  0.6161755323410034\n",
      "epoch:  971  train loss:  0.5643178224563599\n",
      "epoch:  981  train loss:  0.5343989729881287\n",
      "epoch:  991  train loss:  0.8290833234786987\n"
     ]
    }
   ],
   "source": [
    "for epoch in np.arange(0,1000):\n",
    "    for i, batch in enumerate(data_loader, 1):\n",
    "      # Forward pass: Compute predicted y by passing x to the model\n",
    "      y_pred_prob = model(batch[0].float())\n",
    "\n",
    "      # Compute and print loss\n",
    "      loss = criterion(y_pred_prob, batch[1].float())\n",
    "\n",
    "      # Zero gradients, perform a backward pass, and update the weights.\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # perform a backward pass (backpropagation)\n",
    "      loss.backward()\n",
    "\n",
    "      # Update the parameters\n",
    "      optimizer.step()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "          print('epoch: ', epoch+1,' train loss: ', loss.item())\n",
    "    #if loss.item() < 0.1:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4403, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683180986915,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "Vfr6de9mDtuj",
    "outputId": "58ebe732-7c5e-4fbe-8817-1aabc33f86f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_torch_test = torch.from_numpy(X_scl_tst)\n",
    "type(X_torch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683180987636,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "BTktES18ZXq0",
    "outputId": "063fc54a-1592-4be3-bcaf-3fa693d859d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_output = model(X_torch_test.float()) # Equivalent predict_proba / predict\n",
    "type(lin_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 6])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1411e-01, 2.4624e-02, 5.4067e-07, 1.5029e-23, 7.2374e-01, 3.7527e-02],\n",
       "        [4.4063e-16, 3.2293e-06, 1.6834e-10, 1.0000e+00, 8.7875e-20, 2.4128e-24],\n",
       "        [2.6499e-01, 7.2592e-01, 1.0128e-08, 4.2766e-22, 1.6886e-07, 9.0849e-03],\n",
       "        [7.6102e-01, 5.1895e-02, 5.7551e-10, 3.2312e-28, 1.8194e-05, 1.8706e-01],\n",
       "        [6.4085e-01, 2.3541e-02, 1.4440e-09, 1.0670e-27, 8.7336e-05, 3.3552e-01],\n",
       "        [3.9525e-01, 5.9887e-01, 2.5424e-10, 8.0318e-27, 1.6176e-07, 5.8781e-03],\n",
       "        [1.5963e-02, 4.1863e-01, 5.4470e-01, 1.6534e-03, 1.4755e-02, 4.2986e-03],\n",
       "        [4.9045e-02, 9.5086e-01, 1.7901e-09, 1.8854e-23, 1.7806e-07, 9.7978e-05],\n",
       "        [7.0805e-01, 7.6827e-02, 1.1063e-08, 3.2346e-25, 1.0340e-04, 2.1502e-01],\n",
       "        [5.4450e-01, 4.4324e-01, 8.6028e-11, 4.3546e-28, 8.9450e-08, 1.2260e-02],\n",
       "        [8.0955e-13, 2.8016e-05, 9.4125e-07, 9.9997e-01, 5.5367e-12, 3.3184e-19],\n",
       "        [7.2028e-04, 9.9928e-01, 6.0537e-11, 1.2717e-19, 6.3353e-14, 1.6713e-07],\n",
       "        [4.3014e-02, 9.5679e-01, 1.2120e-08, 1.0466e-20, 8.0223e-08, 1.9844e-04],\n",
       "        [7.2865e-01, 3.4517e-02, 1.8316e-08, 1.4324e-26, 1.1147e-02, 2.2568e-01],\n",
       "        [4.1650e-01, 5.6173e-01, 8.9082e-09, 5.4296e-23, 5.9061e-07, 2.1770e-02],\n",
       "        [1.8514e-11, 9.8093e-05, 6.9559e-06, 9.9989e-01, 8.3430e-11, 5.2201e-17],\n",
       "        [1.7985e-18, 5.6347e-07, 6.3870e-13, 1.0000e+00, 1.5797e-24, 3.9357e-28],\n",
       "        [5.4360e-01, 4.2861e-01, 1.2215e-08, 5.7414e-24, 1.1898e-05, 2.7777e-02],\n",
       "        [7.5968e-03, 2.8332e-01, 6.8365e-01, 1.8370e-02, 4.8951e-03, 2.1709e-03],\n",
       "        [2.5541e-01, 5.4046e-01, 2.9073e-03, 3.8821e-12, 1.3700e-01, 6.4224e-02],\n",
       "        [5.5114e-01, 1.8344e-01, 2.1296e-06, 3.9260e-19, 4.3233e-04, 2.6499e-01],\n",
       "        [1.3993e-22, 2.7887e-08, 4.4464e-17, 1.0000e+00, 1.1384e-32, 1.2037e-34],\n",
       "        [3.8780e-01, 6.0150e-01, 1.2353e-07, 3.0524e-22, 2.9707e-04, 1.0402e-02],\n",
       "        [2.4134e-02, 9.7575e-01, 1.6826e-07, 9.0723e-18, 3.3049e-07, 1.2018e-04],\n",
       "        [3.3365e-02, 9.6659e-01, 4.3256e-10, 4.5987e-24, 1.6877e-08, 4.4223e-05],\n",
       "        [7.2798e-01, 2.2976e-01, 2.3907e-10, 6.1884e-28, 8.6954e-07, 4.2266e-02],\n",
       "        [8.3222e-02, 5.0350e-01, 5.0011e-02, 1.7242e-08, 3.4577e-01, 1.7499e-02],\n",
       "        [7.1768e-01, 2.0552e-01, 4.2679e-09, 1.7626e-25, 1.2929e-05, 7.6782e-02],\n",
       "        [6.7431e-01, 1.4155e-01, 2.6925e-08, 1.5663e-23, 2.8720e-05, 1.8411e-01],\n",
       "        [7.7967e-01, 1.8335e-01, 4.5582e-11, 7.9978e-30, 5.2758e-07, 3.6973e-02],\n",
       "        [5.8321e-01, 1.6729e-01, 3.6493e-07, 1.1900e-20, 7.9324e-05, 2.4942e-01],\n",
       "        [4.8338e-10, 3.6210e-04, 5.5940e-05, 9.9958e-01, 1.4100e-09, 1.0173e-14],\n",
       "        [6.7540e-01, 2.9956e-01, 1.1125e-10, 2.1283e-28, 3.0535e-07, 2.5034e-02],\n",
       "        [3.1097e-02, 2.0746e-01, 9.6815e-04, 2.7860e-13, 7.5937e-01, 1.1043e-03],\n",
       "        [2.9589e-01, 6.9186e-01, 1.4370e-08, 6.2960e-22, 2.8203e-07, 1.2244e-02],\n",
       "        [3.5726e-01, 6.3901e-01, 3.3249e-11, 3.2473e-28, 1.1842e-08, 3.7355e-03],\n",
       "        [7.3687e-01, 1.3338e-01, 3.2795e-09, 9.1247e-26, 1.0556e-05, 1.2973e-01],\n",
       "        [7.0442e-01, 2.4659e-01, 6.5311e-10, 7.5368e-27, 1.3341e-06, 4.8995e-02],\n",
       "        [5.4723e-01, 4.4810e-01, 1.9369e-12, 7.9106e-32, 8.8958e-09, 4.6684e-03],\n",
       "        [4.6670e-01, 4.6532e-01, 2.1642e-07, 3.9572e-20, 6.9852e-06, 6.7978e-02],\n",
       "        [9.5127e-02, 9.0441e-01, 1.5603e-09, 1.2428e-23, 8.5234e-08, 4.6567e-04],\n",
       "        [6.7744e-01, 1.2416e-02, 2.3720e-10, 2.2557e-30, 2.1965e-04, 3.0992e-01],\n",
       "        [8.5511e-01, 5.8863e-02, 2.1907e-11, 1.5392e-31, 2.8543e-06, 8.6024e-02],\n",
       "        [6.7901e-01, 4.2514e-02, 1.8399e-08, 1.4976e-25, 1.0379e-03, 2.7744e-01],\n",
       "        [3.7992e-10, 3.2882e-04, 4.7961e-05, 9.9962e-01, 1.1444e-09, 6.8927e-15],\n",
       "        [1.9634e-12, 8.1291e-05, 6.7426e-08, 9.9992e-01, 8.2462e-16, 1.8086e-18],\n",
       "        [2.8074e-01, 7.1664e-01, 5.0926e-11, 2.1193e-27, 7.8234e-09, 2.6137e-03],\n",
       "        [1.9307e-01, 8.0387e-01, 3.5435e-08, 1.0254e-21, 4.3207e-06, 3.0534e-03],\n",
       "        [2.6773e-01, 7.2487e-01, 4.2043e-09, 5.6162e-23, 1.0140e-07, 7.3904e-03],\n",
       "        [2.2564e-02, 4.8940e-01, 4.5639e-01, 4.2740e-04, 2.5337e-02, 5.8846e-03],\n",
       "        [6.2687e-01, 8.1788e-02, 1.2697e-07, 9.8396e-23, 4.3809e-04, 2.9091e-01],\n",
       "        [5.4380e-01, 2.0085e-01, 3.1901e-06, 9.9779e-19, 5.6110e-04, 2.5478e-01],\n",
       "        [2.4893e-02, 5.0952e-01, 4.2922e-01, 2.8075e-04, 2.9662e-02, 6.4289e-03],\n",
       "        [6.6983e-01, 3.2026e-01, 5.0177e-12, 1.6401e-31, 5.4705e-08, 9.9088e-03],\n",
       "        [3.7797e-02, 5.8760e-01, 3.0554e-01, 3.6381e-05, 5.9704e-02, 9.3190e-03],\n",
       "        [2.8090e-01, 7.1652e-01, 4.8160e-11, 1.8632e-27, 7.5738e-09, 2.5795e-03],\n",
       "        [1.8477e-27, 2.5707e-10, 7.9080e-20, 1.0000e+00, 8.4922e-36, 1.4616e-42],\n",
       "        [6.6785e-01, 1.0793e-01, 1.0512e-06, 8.3883e-22, 2.6337e-02, 1.9789e-01],\n",
       "        [6.0511e-01, 3.8997e-01, 8.3577e-13, 6.8838e-33, 8.2057e-09, 4.9260e-03],\n",
       "        [2.9153e-01, 7.0721e-01, 1.6920e-11, 2.2563e-29, 3.3809e-08, 1.2616e-03],\n",
       "        [6.6849e-01, 2.9786e-01, 3.7250e-10, 3.3821e-27, 6.2814e-07, 3.3653e-02],\n",
       "        [6.7491e-01, 9.4658e-03, 9.2538e-11, 2.0058e-31, 1.6048e-04, 3.1547e-01],\n",
       "        [1.2047e-03, 7.8294e-02, 5.0046e-01, 4.1922e-01, 4.3938e-04, 3.7808e-04],\n",
       "        [8.0043e-01, 1.8166e-01, 2.1784e-12, 7.2868e-33, 8.9335e-08, 1.7907e-02],\n",
       "        [3.7484e-01, 6.1476e-01, 1.2307e-09, 9.6356e-25, 1.2413e-07, 1.0397e-02]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_wt_sum = model(X_torch_test.float()) \n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_proba = softmax(y_wt_sum)\n",
    "pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`detach().numpy()` converts `torch.Tensor` into `numpy` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683181009893,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "poJa_B2lZ9jx",
    "outputId": "0dc829e5-de82-46d4-ff0f-d2384f924d76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 1, 0, 0, 1, 2, 1, 0, 0, 3, 1, 1, 0, 1, 3, 3, 0, 2, 1, 0, 3,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 3, 0, 4, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       3, 3, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 3, 0, 0, 1, 0, 0, 2, 0, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(pred_proba.detach().numpy(), axis=1 )\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_org = np.argmax(y_test, axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1191,
     "status": "ok",
     "timestamp": 1683181041369,
     "user": {
      "displayName": "Sanjay Sane",
      "userId": "07643709861745318184"
     },
     "user_tz": -330
    },
    "id": "z6Xtwll3Dtuk",
    "outputId": "7e332c79-60e1-4206-ea9e-048e54895533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_org,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4590490637623557"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "log_loss(y_test_org, pred_proba.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
