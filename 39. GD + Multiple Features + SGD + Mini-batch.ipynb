{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4cc7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b987de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.2, 1.2, 1, 1.4, -1.5, 0.5, -0.5])\n",
    "y = np.array([5.6, 8.6, 8, 9.2, 0.5, 6.5, 3.5])\n",
    "eta = 0.2\n",
    "w, b = 0.3, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c65b103e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 20.095935714285712, dw = -4.383285714285714, db = -5.7871428571428565\n",
      "1.1766571428571428 1.2574285714285713\n"
     ]
    }
   ],
   "source": [
    "y_pred = b + w*x\n",
    "L = np.mean((y-y_pred)**2)/2\n",
    "dw = -np.mean((y-y_pred)*x)\n",
    "db = -np.mean(y-y_pred)\n",
    "print(f\"Loss = {L}, dw = {dw}, db = {db}\")\n",
    "new_w, new_b = w - eta*dw, b - eta*db\n",
    "print(new_w, new_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57768ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th iteration:\n",
      "Loss = 20.095935714285712, dw = -4.383285714285714, db = -5.7871428571428565\n",
      "w = 0.3, b = 0.1\n",
      "2th iteration:\n",
      "Loss = 10.952997757662391, dw = -3.102535632653061, db = -4.341669795918366\n",
      "w = 1.1766571428571428, b = 1.2574285714285713\n",
      "3th iteration:\n",
      "Loss = 6.009611558539441, dw = -2.1798764403848394, db = -3.269454923731778\n",
      "w = 1.7971642693877552, b = 2.1257625306122447\n",
      "4th iteration:\n",
      "Loss = 3.32644496238763, dw = -1.517217642357694, db = -2.472314915760133\n",
      "w = 2.2331395574647233, b = 2.7796535153586004\n",
      "5th iteration:\n",
      "Loss = 1.862421697322274, dw = -1.0430713807919763, db = -1.8781490589674585\n",
      "w = 2.536583085936262, b = 3.274116498510627\n",
      "6th iteration:\n",
      "Loss = 1.0579802312749422, dw = -0.7053734932628485, db = -1.433974556436208\n",
      "w = 2.745197362094657, b = 3.649746310304119\n",
      "7th iteration:\n",
      "Loss = 0.6118539055559408, dw = -0.46623701050961575, db = -1.1008265298774076\n",
      "w = 2.8862720607472268, b = 3.9365412215913604\n",
      "8th iteration:\n",
      "Loss = 0.36146215017489947, dw = -0.2981185783872678, db = -0.8500227917827231\n",
      "w = 2.97951946284915, b = 4.156706527566842\n",
      "9th iteration:\n",
      "Loss = 0.21878647813951807, dw = -0.1810178641099902, db = -0.6604275839893009\n",
      "w = 3.0391431785266034, b = 4.326711085923386\n",
      "10th iteration:\n",
      "Loss = 0.13596771317963877, dw = -0.10043209593495495, db = -0.5164466075499269\n",
      "w = 3.0753467513486017, b = 4.458796602721247\n",
      "11th iteration:\n",
      "Loss = 0.08683021326976892, dw = -0.04586255401675083, db = -0.40655746259278785\n",
      "w = 3.0954331705355926, b = 4.562085924231232\n",
      "12th iteration:\n",
      "Loss = 0.0569457917433155, dw = -0.009724441806926396, db = -0.32223214509598647\n",
      "w = 3.104605681338943, b = 4.64339741674979\n",
      "13th iteration:\n",
      "Loss = 0.038279964967667786, dw = 0.013448491630576154, db = -0.2571466813294763\n",
      "w = 3.106550569700328, b = 4.707843845768987\n",
      "14th iteration:\n",
      "Loss = 0.026299662085132566, dw = 0.02758399769440261, db = -0.2066011030850198\n",
      "w = 3.103860871374213, b = 4.759273182034882\n",
      "15th iteration:\n",
      "Loss = 0.018405094819252035, dw = 0.035494100370767924, db = -0.16709354517364852\n",
      "w = 3.0983440718353323, b = 4.800593402651885\n",
      "16th iteration:\n",
      "Loss = 0.013075415489647428, dw = 0.03918303100601287, db = -0.13600730559185456\n",
      "w = 3.091245251761179, b = 4.834012111686615\n",
      "17th iteration:\n",
      "Loss = 0.009400214835485058, dw = 0.040071339861099974, db = -0.11138072936816432\n",
      "w = 3.083408645559976, b = 4.861213572804986\n",
      "18th iteration:\n",
      "Loss = 0.006820379388128463, dw = 0.039158846830969894, db = -0.09173784297111835\n",
      "w = 3.075394377587756, b = 4.883489718678619\n",
      "19th iteration:\n",
      "Loss = 0.0049831336138752135, dw = 0.03714298769150997, db = -0.07596357002578699\n",
      "w = 3.067562608221562, b = 4.901837287272842\n",
      "20th iteration:\n",
      "Loss = 0.003659787994669, dw = 0.03450464853600575, db = -0.063211680926072\n",
      "w = 3.06013401068326, b = 4.9170300012779995\n",
      "21th iteration:\n",
      "Loss = 0.0026982367327188055, dw = 0.031570318340465205, db = -0.052836793073223705\n",
      "w = 3.053233080976059, b = 4.929672337463214\n",
      "22th iteration:\n",
      "Loss = 0.0019949404206157503, dw = 0.028557005060478667, db = -0.04434405537809522\n",
      "w = 3.0469190173079657, b = 4.9402396960778585\n",
      "23th iteration:\n",
      "Loss = 0.0014779982814683344, dw = 0.025604618231471903, db = -0.037351847492165344\n",
      "w = 3.04120761629587, b = 4.949108507153477\n",
      "24th iteration:\n",
      "Loss = 0.0010966483562195148, dw = 0.022799248064263228, db = -0.031564067191800174\n",
      "w = 3.0360866926495755, b = 4.9565788766519105\n",
      "25th iteration:\n",
      "Loss = 0.0008145751612090791, dw = 0.020189841234522825, db = -0.026749490054806584\n",
      "w = 3.031526843036723, b = 4.96289169009027\n",
      "26th iteration:\n",
      "Loss = 0.0006055287265789208, dw = 0.017800094624518342, db = -0.02272635303925652\n",
      "w = 3.0274888747898183, b = 4.968241588101232\n",
      "27th iteration:\n",
      "Loss = 0.00045038454263978203, dw = 0.01563689267137546, db = -0.01935080293530232\n",
      "w = 3.0239288558649147, b = 4.972786858709083\n",
      "28th iteration:\n",
      "Loss = 0.00033512655014660513, dw = 0.013696252341203875, db = -0.016508209580932638\n",
      "w = 3.0208014773306395, b = 4.976657019296143\n",
      "29th iteration:\n",
      "Loss = 0.0002494372792105937, dw = 0.011967475989857927, db = -0.014106607104311093\n",
      "w = 3.0180622268623987, b = 4.979958661212329\n",
      "30th iteration:\n",
      "Loss = 0.00018569721179529552, dw = 0.010436020103367393, db = -0.01207171981992529\n",
      "w = 3.015668731664427, b = 4.9827799826331916\n",
      "31th iteration:\n",
      "Loss = 0.00013826593986126896, dw = 0.009085447847442309, db = -0.010343171462732543\n",
      "w = 3.0135815276437534, b = 4.985194326597177\n",
      "32th iteration:\n",
      "Loss = 0.00010296090456723584, dw = 0.007898731400047066, db = -0.00887158088587484\n",
      "w = 3.0117644380742647, b = 4.987262960889724\n",
      "33th iteration:\n",
      "Loss = 7.667671482180813e-05, dw = 0.006859095893509583, db = -0.007616324200702669\n",
      "w = 3.0101846917942554, b = 4.989037277066899\n"
     ]
    }
   ],
   "source": [
    "eta = 0.2\n",
    "w, b = 0.3, 0.1\n",
    "for i in range(100):\n",
    "    y_pred = b + w*x\n",
    "    L = np.mean((y-y_pred)**2)/2\n",
    "    dw = -np.mean((y-y_pred)*x)\n",
    "    db = -np.mean(y-y_pred)\n",
    "    print(f\"{i+1}th iteration:\")\n",
    "    print(f\"Loss = {L}, dw = {dw}, db = {db}\")\n",
    "    print(f\"w = {w}, b = {b}\")\n",
    "    if L < 0.0001:\n",
    "        break\n",
    "    new_w, new_b = w - eta*dw, b - eta*db\n",
    "    w, b = new_w, new_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08829391",
   "metadata": {},
   "source": [
    "2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d966b48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th iteration:\n",
      "Loss = 51.648482, dw1 = -3.758833333333333,dw2 = -4.9159266666666666, db = -5.774000000000001\n",
      "w1 = 0.3,w2 = 0.1, b = -0.3\n",
      "2th iteration:\n",
      "Loss = 38.43411825021881, dw1 = -3.332391547901234,dw2 = -4.391041378261728, db = -4.5717798133333325\n",
      "w1 = 1.0517666666666667,w2 = 1.0831853333333334, b = 0.8548000000000002\n",
      "3th iteration:\n",
      "Loss = 28.94345564497027, dw1 = -2.9582158539558954,dw2 = -3.924583124392386, db = -3.6153178524311302\n",
      "w1 = 1.7182449762469136,w2 = 1.9613936089856792, b = 1.7691559626666669\n",
      "4th iteration:\n",
      "Loss = 22.033811389234597, dw1 = -2.6292014182283214,dw2 = -3.5095926080902573, db = -2.8548229571565606\n",
      "w1 = 2.3098881470380928,w2 = 2.7463102338641563, b = 2.492219533152893\n",
      "5th iteration:\n",
      "Loss = 16.936248618102248, dw1 = -2.339325570199756,dw2 = -3.140022968300052, db = -2.2505471663267853\n",
      "w1 = 2.835728430683757,w2 = 3.4482287554822078, b = 3.063184124584205\n",
      "6th iteration:\n",
      "Loss = 13.128087535303667, dw1 = -2.083465507300872,dw2 = -2.810605844335851, db = -1.7707644314228304\n",
      "w1 = 3.303593544723708,w2 = 4.0762333491422185, b = 3.513293557849562\n",
      "7th iteration:\n",
      "Loss = 10.250022012772584, dw1 = -1.8572490483792854,dw2 = -2.5167393270284046, db = -1.3901556783765838\n",
      "w1 = 3.7202866461838826,w2 = 4.638354518009389, b = 3.8674464441341283\n",
      "8th iteration:\n",
      "Loss = 8.052006868178097, dw1 = -1.656932160667123,dw2 = -2.254393910520167, db = -1.088518573563417\n",
      "w1 = 4.091736455859739,w2 = 5.14170238341507, b = 4.145477579809445\n",
      "9th iteration:\n",
      "Loss = 6.357747815434804, dw1 = -1.4792982087526965,dw2 = -2.020033287288394, db = -0.8497367494230226\n",
      "w1 = 4.423122887993164,w2 = 5.592581165519103, b = 4.363181294522128\n",
      "10th iteration:\n",
      "Loss = 5.0412559671755215, dw1 = -1.321574855425953,dw2 = -1.8105474165437556, db = -0.660956350876314\n",
      "w1 = 4.718982529743703,w2 = 5.996587822976782, b = 4.533128644406733\n",
      "11th iteration:\n",
      "Loss = 4.011255648181769, dw1 = -1.1813653319231259,dw2 = -1.6231957704535538, db = -0.511928237313704\n",
      "w1 = 4.983297500828893,w2 = 6.358697306285533, b = 4.665319914581996\n",
      "12th iteration:\n",
      "Loss = 3.2007272881475557, dw1 = -1.0565914275990649,dw2 = -1.4555590459392416, db = -0.39448254499082436\n",
      "w1 = 5.219570567213519,w2 = 6.683336460376244, b = 4.767705562044737\n",
      "13th iteration:\n",
      "Loss = 2.5598262558178897, dw1 = -0.9454460572554275,dw2 = -1.3054979399401112, db = -0.30210900362479043\n",
      "w1 = 5.430888852733331,w2 = 6.974448269564093, b = 4.846602071042902\n",
      "14th iteration:\n",
      "Loss = 2.051035512553907, dw1 = -0.8463536729349656,dw2 = -1.171117837322108, db = -0.2296217464473978\n",
      "w1 = 5.619978064184417,w2 = 7.235547857552115, b = 4.90702387176786\n",
      "15th iteration:\n",
      "Loss = 1.6458076353801272, dw1 = -0.7579371157132435,dw2 = -1.0507384645133055, db = -0.17289162475392406\n",
      "w1 = 5.78924879877141,w2 = 7.469771425016536, b = 4.95294822105734\n",
      "16th iteration:\n",
      "Loss = 1.3222086439600438, dw1 = -0.6789897676937435,dw2 = -0.9428677276682222, db = -0.12863245171698043\n",
      "w1 = 5.940836221914059,w2 = 7.679919117919198, b = 4.987526546008125\n",
      "17th iteration:\n",
      "Loss = 1.063242470748625, dw1 = -0.6084520777019604,dw2 = -0.8461790890882661, db = -0.09423032824131114\n",
      "w1 = 6.076634175452807,w2 = 7.868492663452843, b = 5.013253036351521\n",
      "18th iteration:\n",
      "Loss = 0.8556430785523117, dw1 = -0.5453917062179157,dw2 = -0.7594919456868108, db = -0.06760738363785287\n",
      "w1 = 6.1983245909932,w2 = 8.037728481270497, b = 5.0320991019997825\n",
      "19th iteration:\n",
      "Loss = 0.6889918335179948, dw1 = -0.48898667400601514,dw2 = -0.6817545632510175, db = -0.047113005956729646\n",
      "w1 = 6.307402932236783,w2 = 8.189626870407858, b = 5.045620578727353\n",
      "20th iteration:\n",
      "Loss = 0.5550640618348919, dw1 = -0.438511011203226,dw2 = -0.6120291939505871, db = -0.03143702889882114\n",
      "w1 = 6.405200267037985,w2 = 8.325977783058061, b = 5.055043179918699\n",
      "21th iteration:\n",
      "Loss = 0.4473392922447291, dw1 = -0.3933224945262302,dw2 = -0.5494790650595749, db = -0.019540454619124015\n",
      "w1 = 6.49290246927863,w2 = 8.448383621848178, b = 5.061330585698463\n",
      "22th iteration:\n",
      "Loss = 0.3606300121290943, dw1 = -0.35285213393648635,dw2 = -0.49335697667388584, db = -0.010600180619917543\n",
      "w1 = 6.571566968183876,w2 = 8.558279434860093, b = 5.065238676622288\n",
      "23th iteration:\n",
      "Loss = 0.29079739110328007, dw1 = -0.31659512991232946,dw2 = -0.442995287325068, db = -0.0039649092032215\n",
      "w1 = 6.642137394971173,w2 = 8.656950830194871, b = 5.067358712746271\n",
      "24th iteration:\n",
      "Loss = 0.2345316489322789, dw1 = -0.2841030711099557,dw2 = -0.3977971004246098, db = 0.00088001451119597\n",
      "w1 = 6.705456420953639,w2 = 8.745549887659886, b = 5.068151694586915\n",
      "25th iteration:\n",
      "Loss = 0.18918105479432445, dw1 = -0.2549771818102388,dw2 = -0.35722849272558876, db = 0.004340636520905816\n",
      "w1 = 6.7622770351756305,w2 = 8.825109307744807, b = 5.067975691684676\n",
      "26th iteration:\n",
      "Loss = 0.15261791385256723, dw1 = -0.22886246088058804,dw2 = -0.32081164951403995, db = 0.006736738020278033\n",
      "w1 = 6.813272471537679,w2 = 8.896555006289924, b = 5.067107564380495\n",
      "27th iteration:\n",
      "Loss = 0.12313296081101618, dw1 = -0.2054425804246162,dw2 = -0.28811879089390613, db = 0.0083196383240566\n",
      "w1 = 6.859044963713797,w2 = 8.960717336192733, b = 5.0657602167764395\n",
      "28th iteration:\n",
      "Loss = 0.09935175748031841, dw1 = -0.18443543396837273,dw2 = -0.2587667899984386, db = 0.009286374045279367\n",
      "w1 = 6.90013347979872,w2 = 9.018341094371515, b = 5.064096289111628\n",
      "29th iteration:\n",
      "Loss = 0.08016826005655078, dw1 = -0.16558924184252394,dw2 = -0.23241239780888776, db = 0.009790987155904008\n",
      "w1 = 6.937020566592395,w2 = 9.070094452371203, b = 5.062239014302572\n",
      "30th iteration:\n",
      "Loss = 0.0646918673947497, dw1 = -0.14867913609184993,dw2 = -0.2087480009449159, db = 0.009953506938766088\n",
      "w1 = 6.9701384149609,w2 = 9.11657693193298, b = 5.0602808168713915\n",
      "31th iteration:\n",
      "Loss = 0.05220510918892374, dw1 = -0.13350415936246784,dw2 = -0.1874978486822843, db = 0.009867092913821152\n",
      "w1 = 6.99987424217927,w2 = 9.158326532121963, b = 5.058290115483638\n",
      "32th iteration:\n",
      "Loss = 0.042129767932499056, dw1 = -0.11988462225603178,dw2 = -0.16841469385576724, db = 0.009603711622045763\n",
      "w1 = 7.026575074051763,w2 = 9.19582610185842, b = 5.056316696900874\n",
      "33th iteration:\n",
      "Loss = 0.033999709611500194, dw1 = -0.10765977198057204,dw2 = -0.15127679946727537, db = 0.009218644907908979\n",
      "w1 = 7.05055199850297,w2 = 9.229509040629575, b = 5.0543959545764645\n",
      "34th iteration:\n",
      "Loss = 0.0274390663053647, dw1 = -0.0966857320784286,dw2 = -0.13588526894450403, db = 0.008754067245067044\n",
      "w1 = 7.072083952899084,w2 = 9.25976440052303, b = 5.052552225594883\n",
      "35th iteration:\n",
      "Loss = 0.022144698252562534, dw1 = -0.08683367882296841,dw2 = -0.12206166325143941, db = 0.008241881654726812\n",
      "w1 = 7.09142109931477,w2 = 9.28694145431193, b = 5.050801412145869\n",
      "36th iteration:\n",
      "Loss = 0.01787208428082963, dw1 = -0.077988224750259,dw2 = -0.10964587257667346, db = 0.007705965438514229\n",
      "w1 = 7.108787835079363,w2 = 9.311353786962218, b = 5.049153035814924\n",
      "37th iteration:\n",
      "Loss = 0.014423962921114355, dw1 = -0.07004598389429326,dw2 = -0.0984942142326186, db = 0.007163946343467309\n",
      "w1 = 7.1243854800294155,w2 = 9.333282961477552, b = 5.047611842727221\n",
      "38th iteration:\n",
      "Loss = 0.01164118315273889, dw1 = -0.06291429675877801,dw2 = -0.08847773178282015, db = 0.006628605342182148\n",
      "w1 = 7.138394676808274,w2 = 9.352981804324076, b = 5.046179053458528\n",
      "39th iteration:\n",
      "Loss = 0.009395331867695183, dw1 = -0.05651009599411409,dw2 = -0.07948067335405365, db = 0.0061089827048984805\n",
      "w1 = 7.150977536160029,w2 = 9.370677350680639, b = 5.044853332390091\n",
      "40th iteration:\n",
      "Loss = 0.007582791060051358, dw1 = -0.05075889624426879,dw2 = -0.0713991296502104, db = 0.005611248470568331\n",
      "w1 = 7.162279555358852,w2 = 9.38657348535145, b = 5.043631535849111\n",
      "41th iteration:\n",
      "Loss = 0.006119946220835576, dw1 = -0.04559389375778126,dw2 = -0.0641398144207856, db = 0.005139385998197188\n",
      "w1 = 7.1724313346077055,w2 = 9.400853311281493, b = 5.042509286154997\n",
      "42th iteration:\n",
      "Loss = 0.004939322128642952, dw1 = -0.04095516318004826,dw2 = -0.057618972093966214, db = 0.004695727364977698\n",
      "w1 = 7.181550113359262,w2 = 9.41368127416565, b = 5.041481408955358\n",
      "43th iteration:\n",
      "Loss = 0.0039864660275101636, dw1 = -0.03678894050964954,dw2 = -0.051761399001587584, db = 0.0042813714679702745\n",
      "w1 = 7.189741145995272,w2 = 9.425205068584443, b = 5.0405422634823625\n",
      "44th iteration:\n",
      "Loss = 0.0032174333087875923, dw1 = -0.03304698255030435,dw2 = -0.04649956613307468, db = 0.0038965093774763204\n",
      "w1 = 7.197098934097202,w2 = 9.43555734838476, b = 5.039685989188769\n",
      "45th iteration:\n",
      "Loss = 0.0025967590183772218, dw1 = -0.029685994355839983,dw2 = -0.041772832685761, db = 0.0035406764597503138\n",
      "w1 = 7.203708330607262,w2 = 9.444857261611375, b = 5.038906687313274\n",
      "46th iteration:\n",
      "Loss = 0.00209582118206055, dw1 = -0.026667117176000905,dw2 = -0.037526740853005044, db = 0.003212946776729586\n",
      "w1 = 7.20964552947843,w2 = 9.453211828148527, b = 5.038198552021323\n",
      "47th iteration:\n",
      "Loss = 0.001691520180541328, dw1 = -0.023955470289349884,dw2 = -0.03371238332958084, db = 0.002912082074850053\n",
      "w1 = 7.21497895291363,w2 = 9.460717176319129, b = 5.037555962665977\n",
      "48th iteration:\n",
      "Loss = 0.0013652130886242925, dw1 = -0.021519740875111843,dw2 = -0.030285835932922566, db = 0.002636645129433024\n",
      "w1 = 7.2197700469715,w2 = 9.467459652985045, b = 5.036973546251008\n",
      "49th iteration:\n",
      "Loss = 0.001101853719276544, dw1 = -0.01933181674485963,dw2 = -0.02720764855385328, db = 0.002385085184163138\n",
      "w1 = 7.224073995146522,w2 = 9.47351682017163, b = 5.036446217225121\n",
      "50th iteration:\n",
      "Loss = 0.0008892986428936588, dw1 = -0.017366457340974324,dw2 = -0.024442388374077282, db = 0.0021558016118871314\n",
      "w1 = 7.227940358495494,w2 = 9.4789583498824, b = 5.035969200188289\n",
      "51th iteration:\n",
      "Loss = 0.0007177471335363262, dw1 = -0.015600998923303275,dw2 = -0.021958229931004648, db = 0.0019471906396677063\n",
      "w1 = 7.231413649963689,w2 = 9.483846827557215, b = 5.035538039865911\n",
      "52th iteration:\n",
      "Loss = 0.0005792891872769814, dw1 = -0.014015090318043943,dw2 = -0.01972658718291129, db = 0.0017576789608294784\n",
      "w1 = 7.23453384974835,w2 = 9.488238473543417, b = 5.035148601737978\n",
      "53th iteration:\n",
      "Loss = 0.0004675407524280575, dw1 = -0.012590456001858463,dw2 = -0.01772178323737446, db = 0.001585747246210234\n",
      "w1 = 7.237336867811958,w2 = 9.492183790979999, b = 5.0347970659458126\n",
      "54th iteration:\n",
      "Loss = 0.00037734934000005916, dw1 = -0.011310683646495033,dw2 = -0.015920753860500736, db = 0.0014299459234614175\n",
      "w1 = 7.23985495901233,w2 = 9.495728147627474, b = 5.03447991649657\n",
      "55th iteration:\n",
      "Loss = 0.0003045564325481295, dw1 = -0.01016103356081316,dw2 = -0.014302781290115762, db = 0.0012889050829556492\n",
      "w1 = 7.242117095741629,w2 = 9.498912298399574, b = 5.034193927311878\n",
      "56th iteration:\n",
      "Loss = 0.0002458057314224998, dw1 = -0.00912826774311858,dw2 = -0.01284925523823915, db = 0.0011613399645523438\n",
      "w1 = 7.244149302453792,w2 = 9.501772854657597, b = 5.033936146295287\n",
      "57th iteration:\n",
      "Loss = 0.00019838839785894162, dw1 = -0.008200496501563103,dw2 = -0.011543458291761349, db = 0.0010460531595500645\n",
      "w1 = 7.245974956002415,w2 = 9.504342705705245, b = 5.033703878302377\n",
      "58th iteration:\n",
      "Loss = 0.00016011815026383287, dw1 = -0.007367040817846661,dw2 = -0.010370373209539634, db = 0.0009419344092384651\n",
      "w1 = 7.247615055302728,w2 = 9.506651397363598, b = 5.033494667670467\n",
      "59th iteration:\n",
      "Loss = 0.00012923045741951118, dw1 = -0.00661830882281014,dw2 = -0.009316509872853509, db = 0.0008479586819885032\n",
      "w1 = 7.249088463466298,w2 = 9.508725472005505, b = 5.033306280788619\n",
      "60th iteration:\n",
      "Loss = 0.00010430117883238109, dw1 = -0.005945684924663502,dw2 = -0.00836974987774276, db = 0.000763183053564287\n",
      "w1 = 7.25041212523086,w2 = 9.510588773980075, b = 5.033136689052221\n",
      "61th iteration:\n",
      "Loss = 8.418090041589602e-05, dw1 = -0.005341430283919736,dw2 = -0.007519206964998915, db = 0.0006867427918547442\n",
      "w1 = 7.251601262215793,w2 = 9.512262723955624, b = 5.032984052441509\n"
     ]
    }
   ],
   "source": [
    "x1 = np.linspace(-0.6, 0.7, 10)\n",
    "x2 = np.linspace(-0.9, 0.92, 10)\n",
    "y = 5 + 8*x1 + 9*x2\n",
    "\n",
    "eta = 0.2\n",
    "w1, w2, b = 0.3, 0.1, -0.3\n",
    "for i in range(100):\n",
    "    y_pred = b + w1*x1 + w2*x2\n",
    "    L = np.mean((y-y_pred)**2)/2\n",
    "    dw1 = -np.mean((y-y_pred)*x1)\n",
    "    dw2 = -np.mean((y-y_pred)*x2)\n",
    "    db = -np.mean(y-y_pred)\n",
    "    print(f\"{i+1}th iteration:\")\n",
    "    print(f\"Loss = {L}, dw1 = {dw1},dw2 = {dw2}, db = {db}\")\n",
    "    print(f\"w1 = {w1},w2 = {w2}, b = {b}\")\n",
    "    if L < 0.0001:\n",
    "        break\n",
    "    new_w1,new_w2, new_b = w1 - eta*dw1,w2 - eta*dw2 ,b - eta*db\n",
    "    w1, w2, b = new_w1,new_w2, new_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c94bb",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e02bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =  2.8344904011609597 , b = 4.37409141363968\n",
      "Loss =  0.2439872496626577\n",
      "w =  2.999644499916011 , b = 4.894869035610247\n",
      "Loss =  0.005538604792553377\n",
      "w =  3.003120495925965 , b = 4.978489237403861\n",
      "Loss =  0.00021430224311760386\n",
      "w =  3.0010085087073324 , b = 4.995150461760576\n",
      "Loss =  1.0674381186758593e-05\n",
      "Algo stopped at 4th iteration as Loss < Tolerance 0.0001\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.2, 1.2, 1, 1.4, -1.5, 0.5, -0.5])\n",
    "y = np.array([5.6, 8.6, 8, 9.2, 0.5, 6.5, 3.5])\n",
    "eta = 0.2\n",
    "w, b = 0.3, 0.1\n",
    "tol = 0.0001\n",
    "n = len(x)\n",
    "for i in range(0, 50):\n",
    "    for j in range(0, len(x)):\n",
    "        y_pred = w*x[j] + b\n",
    "        err = y[j] - y_pred\n",
    "        dw, db = -(err*x[j]), -(err)\n",
    "        new_w, new_b = w - eta*dw, b - eta*db \n",
    "        w, b = new_w, new_b\n",
    "    y_pred_all = w*x + b\n",
    "    err_all = y - y_pred_all\n",
    "    L = np.sum(err_all**2)/(2*n)\n",
    "    print(\"w = \" ,w , \", b =\", b)\n",
    "    print(\"Loss = \", L)\n",
    "    if L < tol:\n",
    "        print(f\"Algo stopped at {i+1}th iteration as Loss < Tolerance {tol}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc879c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0ad8b",
   "metadata": {},
   "source": [
    "### Min-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b09c7d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =  3.0079424602735796 , b = 4.972191579612213\n",
      "Loss =  0.00034648090604227834\n",
      "w =  3.000284231813902 , b = 4.999566868938669\n",
      "Loss =  9.484121890159695e-08\n",
      "Algo stopped at 2th iteration as Loss < Tolerance 0.0001\n"
     ]
    }
   ],
   "source": [
    "w, b = 0.3, 0.1\n",
    "batches = [[0,6],[3,1,5],[4,2]]\n",
    "tol = 0.0001\n",
    "for i in range(0, 50):\n",
    "    for j in range(0, len(x)):\n",
    "        for batch in batches:\n",
    "            y_pred = w*x[batch] + b\n",
    "            err = y[batch] - y_pred\n",
    "            dw = -np.sum(err*x[batch])/len(batch)\n",
    "            db = -np.sum(err)/len(batch)\n",
    "            new_w = w - eta*dw \n",
    "            new_b = b - eta*db \n",
    "            w, b = new_w, new_b\n",
    "\n",
    "    y_pred_all = w*x + b\n",
    "    err_all = y - y_pred_all\n",
    "    L = np.sum(err_all**2)/(2*n)\n",
    "    print(\"w = \" ,w , \", b =\", b)\n",
    "    print(\"Loss = \", L)\n",
    "    if L < tol:\n",
    "        print(f\"Algo stopped at {i+1}th iteration as Loss < Tolerance {tol}\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
