{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9fcac5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "from torchsummary import summary\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "os.chdir(\"E:/Training/AV/Big Mart III\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2a6ca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
      "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
      "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
      "       'Outlet_Type', 'Item_Outlet_Sales'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_v9rqX0R.csv\")\n",
    "test = pd.read_csv(\"test_AbJTz2l.csv\")\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6054f1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8523, 12), (5681, 11))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67815a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2d2901af-bc8e-438f-93f9-d83ba26c1283",
       "rows": [
        [
         "Item_Identifier",
         "0"
        ],
        [
         "Item_Weight",
         "1463"
        ],
        [
         "Item_Fat_Content",
         "0"
        ],
        [
         "Item_Visibility",
         "0"
        ],
        [
         "Item_Type",
         "0"
        ],
        [
         "Item_MRP",
         "0"
        ],
        [
         "Outlet_Identifier",
         "0"
        ],
        [
         "Outlet_Establishment_Year",
         "0"
        ],
        [
         "Outlet_Size",
         "2410"
        ],
        [
         "Outlet_Location_Type",
         "0"
        ],
        [
         "Outlet_Type",
         "0"
        ],
        [
         "Item_Outlet_Sales",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                  1463\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  2410\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32828ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "57cf4469-1f5b-49e7-8d13-6a4418b4e875",
       "rows": [
        [
         "Item_Identifier",
         "0"
        ],
        [
         "Item_Weight",
         "976"
        ],
        [
         "Item_Fat_Content",
         "0"
        ],
        [
         "Item_Visibility",
         "0"
        ],
        [
         "Item_Type",
         "0"
        ],
        [
         "Item_MRP",
         "0"
        ],
        [
         "Outlet_Identifier",
         "0"
        ],
        [
         "Outlet_Establishment_Year",
         "0"
        ],
        [
         "Outlet_Size",
         "1606"
        ],
        [
         "Outlet_Location_Type",
         "0"
        ],
        [
         "Outlet_Type",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 11
       }
      },
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                   976\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  1606\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c0a8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_trn = train[['Item_Identifier', 'Item_Weight']]\n",
    "items_trn = items_trn.drop_duplicates()\n",
    "items_tst = test[['Item_Identifier', 'Item_Weight']]\n",
    "items_tst = items_tst.drop_duplicates()\n",
    "items = pd.concat([items_trn, items_tst])\n",
    "items = items.dropna()\n",
    "items = items.drop_duplicates()\n",
    "items.columns = ['Item_Identifier', 'I_Weight']\n",
    "train_1 = train.merge(items, how='left', on='Item_Identifier')\n",
    "train_1 = train_1.drop('Item_Weight', axis=1)\n",
    "outlets = train_1[['Outlet_Identifier', 'Outlet_Establishment_Year',\n",
    "       'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']]\n",
    "outlets = outlets.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10151597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Outlet_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "High",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Medium",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Small",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "All",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "23b58675-5b87-487d-b39b-07d33440587a",
       "rows": [
        [
         "Grocery Store",
         "0",
         "0",
         "722",
         "722"
        ],
        [
         "Supermarket Type1",
         "1857",
         "620",
         "1240",
         "3717"
        ],
        [
         "Supermarket Type2",
         "0",
         "618",
         "0",
         "618"
        ],
        [
         "Supermarket Type3",
         "0",
         "624",
         "0",
         "624"
        ],
        [
         "All",
         "1857",
         "1862",
         "1962",
         "5681"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>High</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Small</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Grocery Store</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>722</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supermarket Type1</th>\n",
       "      <td>1857</td>\n",
       "      <td>620</td>\n",
       "      <td>1240</td>\n",
       "      <td>3717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supermarket Type2</th>\n",
       "      <td>0</td>\n",
       "      <td>618</td>\n",
       "      <td>0</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supermarket Type3</th>\n",
       "      <td>0</td>\n",
       "      <td>624</td>\n",
       "      <td>0</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1857</td>\n",
       "      <td>1862</td>\n",
       "      <td>1962</td>\n",
       "      <td>5681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Outlet_Size        High  Medium  Small   All\n",
       "Outlet_Type                                 \n",
       "Grocery Store         0       0    722   722\n",
       "Supermarket Type1  1857     620   1240  3717\n",
       "Supermarket Type2     0     618      0   618\n",
       "Supermarket Type3     0     624      0   624\n",
       "All                1857    1862   1962  5681"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(df):\n",
    "    df_1 = df.merge(items, how='left', on='Item_Identifier')\n",
    "    df_1 = df_1.drop('Item_Weight', axis=1)\n",
    "\n",
    "    outlets = df_1[['Outlet_Identifier','Outlet_Size']]\n",
    "    outlets = outlets.drop_duplicates()\n",
    "    size_map = {\n",
    "        \"OUT010\": \"Small\",\n",
    "        \"OUT017\": \"High\",\n",
    "        \"OUT045\": \"High\"\n",
    "    }\n",
    "\n",
    "    df_1[\"Outlet_Size\"] = df_1[\"Outlet_Size\"].fillna(\n",
    "        df_1[\"Outlet_Identifier\"].map(size_map)\n",
    "    )\n",
    "\n",
    "    df_1['Item_Fat_Content'] = df_1['Item_Fat_Content'].replace({'reg':'Regular',\n",
    "                                   'LF':'Low Fat',\n",
    "                                   'low fat':'Low Fat'})\n",
    "    return df_1\n",
    "\n",
    "train_1 = clean_data(train)\n",
    "test_1 = clean_data(test)\n",
    "# Validating the processing\n",
    "#pd.crosstab( train_1['Outlet_Type'] , train_1['Outlet_Size'] , margins=True)\n",
    "pd.crosstab( test_1['Outlet_Type'] , test_1['Outlet_Size'] , margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "50326b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8523, 12), (5681, 11))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.shape, test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69ce763e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8523, 12), (5681, 11))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c8a98cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "62e0927c-b084-4394-8a8c-514221b3c56f",
       "rows": [
        [
         "Item_Identifier",
         "0"
        ],
        [
         "Item_Fat_Content",
         "0"
        ],
        [
         "Item_Visibility",
         "0"
        ],
        [
         "Item_Type",
         "0"
        ],
        [
         "Item_MRP",
         "0"
        ],
        [
         "Outlet_Identifier",
         "0"
        ],
        [
         "Outlet_Establishment_Year",
         "0"
        ],
        [
         "Outlet_Size",
         "0"
        ],
        [
         "Outlet_Location_Type",
         "0"
        ],
        [
         "Outlet_Type",
         "0"
        ],
        [
         "I_Weight",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 11
       }
      },
      "text/plain": [
       "Item_Identifier              0\n",
       "Item_Fat_Content             0\n",
       "Item_Visibility              0\n",
       "Item_Type                    0\n",
       "Item_MRP                     0\n",
       "Outlet_Identifier            0\n",
       "Outlet_Establishment_Year    0\n",
       "Outlet_Size                  0\n",
       "Outlet_Location_Type         0\n",
       "Outlet_Type                  0\n",
       "I_Weight                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bf53ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_1.drop(['Item_Identifier',\n",
    "                                 'Outlet_Identifier','Item_Outlet_Sales'], axis=1)\n",
    "y = train_1['Item_Outlet_Sales'].values\n",
    "ohe = OneHotEncoder(sparse_output=False).set_output(transform='pandas')\n",
    "col_trnf = ColumnTransformer([('OHE',ohe, make_column_selector(dtype_include=object) )],\n",
    "                             remainder='passthrough', verbose_feature_names_out=False)\n",
    "col_trnf = col_trnf.set_output(transform='pandas')\n",
    "pipe = Pipeline([('TRNS', col_trnf)])\n",
    "X = pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a3be354",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                    random_state=25)\n",
    "X_scl_trn = scaler_x.fit_transform(X_train)\n",
    "X_scl_tst = scaler_x.transform(X_test)\n",
    "#y_scl_trn = scaler_y.fit_transform(y_train.reshape(-1,1))\n",
    "#y_scl_tst = scaler_y.transform(y_test.reshape(-1,1))\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f812cf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6818, 32])\n",
      "torch.Size([6818, 1])\n",
      "torch.Size([1705, 32])\n",
      "torch.Size([1705, 1])\n"
     ]
    }
   ],
   "source": [
    "X_torch = torch.from_numpy(X_scl_trn)\n",
    "y_torch = torch.from_numpy(y_train)\n",
    "X_torch_test = torch.from_numpy(X_scl_tst)\n",
    "y_torch_test = torch.from_numpy(y_test)\n",
    "print(X_torch.size())\n",
    "print(y_torch.size())\n",
    "print(X_torch_test.size())\n",
    "print(y_torch_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "119dc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_dataset = TensorDataset(X_torch.float(), y_torch.float())\n",
    "torch.manual_seed(25)\n",
    "data_loader = DataLoader(dataset=joint_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "56e4a69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 20]             660\n",
      "              ReLU-2                   [-1, 20]               0\n",
      "       BatchNorm1d-3                   [-1, 20]              40\n",
      "            Linear-4                   [-1, 10]             210\n",
      "              ReLU-5                   [-1, 10]               0\n",
      "       BatchNorm1d-6                   [-1, 10]              20\n",
      "            Linear-7                    [-1, 5]              55\n",
      "              ReLU-8                    [-1, 5]               0\n",
      "            Linear-9                    [-1, 1]               6\n",
      "             ReLU-10                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 991\n",
      "Trainable params: 991\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(25)\n",
    "class MLPRegressor(torch.nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_features, 20)\n",
    "        self.bn1 = nn.BatchNorm1d(20)\n",
    "        self.linear2 = nn.Linear(20, 10)\n",
    "        self.bn2 = nn.BatchNorm1d(10)\n",
    "        self.linear3 = nn.Linear(10, 5)\n",
    "        self.linear4 = nn.Linear(5, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear4(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "model = MLPRegressor(X_scl_trn.shape[1])\n",
    "summary(model, input_size=(X_scl_trn.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75e11f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_torch_test = torch.from_numpy(X_scl_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a5df313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  train loss:  6636763.0  test loss:  7888355.5\n",
      "epoch:  101  train loss:  2004410.0  test loss:  1217829.5\n",
      "epoch:  201  train loss:  1462877.0  test loss:  1218775.5\n",
      "epoch:  301  train loss:  1088200.625  test loss:  1225655.875\n",
      "epoch:  401  train loss:  1145360.0  test loss:  1219377.625\n",
      "epoch:  501  train loss:  1067454.375  test loss:  1221712.625\n",
      "epoch:  601  train loss:  1540305.5  test loss:  1226813.75\n",
      "epoch:  701  train loss:  1250297.625  test loss:  1228604.0\n",
      "epoch:  801  train loss:  1176428.875  test loss:  1226588.75\n",
      "epoch:  901  train loss:  720082.125  test loss:  1234127.75\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "for epoch in np.arange(0,1000):\n",
    "    for i, batch in enumerate(data_loader, 1):\n",
    "      y_pred_prob = model(batch[0].float())\n",
    "      loss = criterion(y_pred_prob, batch[1].float())\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    test_loss = criterion(model(X_torch_test.float()), y_torch_test.float())\n",
    "    if epoch%100 == 0:\n",
    "          print('epoch: ', epoch+1,' train loss: ', loss.item(), \n",
    "                ' test loss: ', test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d1cfecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5861363113477895\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(X_torch_test.float()).detach().numpy()\n",
    "print(r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "97fbbcac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ohe = scaler_x.transform( pipe.transform( test_1 ) )\n",
    "test_ohe_torch = torch.from_numpy(test_ohe)\n",
    "predictions = model(test_ohe_torch.float()).detach().numpy()\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ede5b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv(\"sample_submission_8RXa3c6.csv\")\n",
    "ss['Item_Outlet_Sales'] = predictions.ravel()\n",
    "ss.to_csv(\"bigmart_submission_pytorch_bn.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
